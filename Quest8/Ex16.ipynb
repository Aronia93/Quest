{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMV3T2WQjCagmckyTWbeakp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JihyeLimm/Quest/blob/main/Quest8/Ex16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#16.한국어 데이터로 챗봇 만들기"
      ],
      "metadata": {
        "id": "XEUGGJe4W1dC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 한국어 전처리를 통해 학습 데이터셋을 구축하였다.\t\n",
        ">공백과 특수문자 처리, 토크나이징, 병렬데이터 구축의 과정이 적절히 진행되었다.\n",
        "2. 트랜스포머 모델을 구현하여 한국어 챗봇 모델 학습을 정상적으로 진행하였다.\t\n",
        ">구현한 트랜스포머 모델이 한국어 병렬 데이터 학습 시 안정적으로 수렴하였다.\n",
        "3. 한국어 입력문장에 대해 한국어로 답변하는 함수를 구현하였다.\t\n",
        ">한국어 입력문장에 맥락에 맞는 한국어로 답변을 리턴하였다."
      ],
      "metadata": {
        "id": "KaK-YJsNXMCl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "TEU8R8S8WwWI",
        "outputId": "6b86279c-ce19-4bca-f84d-80db6a9e1d4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/gdrive/MyDrive/AIFFEL/230530'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount = True)\n",
        "os.chdir(\"/gdrive/MyDrive/AIFFEL/230530\")\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from bs4 import BeautifulSoup \n",
        "from tensorflow.keras.preprocessing.text import Tokenizer \n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import urllib.request\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sc3WwYhWZiwP",
        "outputId": "fae4ea9e-d738-43e7-dd60-d160aeb955b1"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "step1. 데이터 수집하기\n",
        ">https://github.com/songys/Chatbot_data/blob/master/ChatbotData.csv"
      ],
      "metadata": {
        "id": "oTFiPgxMYvpX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/gdrive/MyDrive/AIFFEL/230530/ChatbotData .csv\")\n",
        "print('전체 샘플수 :', (len(data)))\n",
        "data.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "DnAahlaHXqKL",
        "outputId": "b87cc390-78da-482a-b753-7e84da12a404"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플수 : 11823\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Q            A  label\n",
              "0        12시 땡!   하루가 또 가네요.      0\n",
              "1   1지망 학교 떨어졌어    위로해 드립니다.      0\n",
              "2  3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a299051f-8763-431d-a547-0aaadb86cb99\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12시 땡!</td>\n",
              "      <td>하루가 또 가네요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1지망 학교 떨어졌어</td>\n",
              "      <td>위로해 드립니다.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3박4일 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a299051f-8763-431d-a547-0aaadb86cb99')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a299051f-8763-431d-a547-0aaadb86cb99 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a299051f-8763-431d-a547-0aaadb86cb99');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "step2. 데이터 전처리하기"
      ],
      "metadata": {
        "id": "o2ZIObfKZ_lx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리 함수\n",
        "def preprocess_sentence(sentence):\n",
        "  # 입력받은 sentence를 소문자로 변경하고 양쪽 공백을 제거\n",
        "  sentence = sentence.strip()  #양쪽 공백 제거\n",
        "\n",
        "  # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
        "  # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
        "  # student와 온점 사이에 거리를 만듭니다.\n",
        "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "\n",
        "  # (a-z, A-Z, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
        "  sentence = re.sub(\"[^0-9가-힣.?!,]\", \" \", sentence)\n",
        "  sentence = sentence.strip()\n",
        "  return sentence"
      ],
      "metadata": {
        "id": "Czxpk9NtZ4om"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#전처리 함수 호출\n",
        "data[\"QQ\"] = data[\"Q\"].apply(lambda x: preprocess_sentence(x))\n",
        "data[\"AA\"] = data[\"A\"].apply(lambda x: preprocess_sentence(x))\n",
        "\n",
        "data.sample(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "id": "2JV-dobqa0yn",
        "outputId": "06780acd-894b-457b-dbd7-2549d7c08c58"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                              Q                               A  label  \\\n",
              "10795  오늘도 짝사랑하는 여자 땜에 술 마시는 중.      술 한잔으로 잊혀질 수 있다면 얼마나 좋을까요.      2   \n",
              "2982                앞으로 어떻게 살지?           잘 될거예요. 당신의 삶을 응원합니다!      0   \n",
              "4990                 학벌이 중요하겠지?  좋으면 좋겠지만 자신의 가치관에 따라 다를 것 같아요.      0   \n",
              "\n",
              "                              QQ                               AA  \n",
              "10795  오늘도 짝사랑하는 여자 땜에 술 마시는 중 .      술 한잔으로 잊혀질 수 있다면 얼마나 좋을까요 .  \n",
              "2982                앞으로 어떻게 살지 ?          잘 될거예요 . 당신의 삶을 응원합니다 !  \n",
              "4990                 학벌이 중요하겠지 ?  좋으면 좋겠지만 자신의 가치관에 따라 다를 것 같아요 .  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9d4a5019-df2d-412f-a238-8e24e57f9375\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>label</th>\n",
              "      <th>QQ</th>\n",
              "      <th>AA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10795</th>\n",
              "      <td>오늘도 짝사랑하는 여자 땜에 술 마시는 중.</td>\n",
              "      <td>술 한잔으로 잊혀질 수 있다면 얼마나 좋을까요.</td>\n",
              "      <td>2</td>\n",
              "      <td>오늘도 짝사랑하는 여자 땜에 술 마시는 중 .</td>\n",
              "      <td>술 한잔으로 잊혀질 수 있다면 얼마나 좋을까요 .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2982</th>\n",
              "      <td>앞으로 어떻게 살지?</td>\n",
              "      <td>잘 될거예요. 당신의 삶을 응원합니다!</td>\n",
              "      <td>0</td>\n",
              "      <td>앞으로 어떻게 살지 ?</td>\n",
              "      <td>잘 될거예요 . 당신의 삶을 응원합니다 !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4990</th>\n",
              "      <td>학벌이 중요하겠지?</td>\n",
              "      <td>좋으면 좋겠지만 자신의 가치관에 따라 다를 것 같아요.</td>\n",
              "      <td>0</td>\n",
              "      <td>학벌이 중요하겠지 ?</td>\n",
              "      <td>좋으면 좋겠지만 자신의 가치관에 따라 다를 것 같아요 .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d4a5019-df2d-412f-a238-8e24e57f9375')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9d4a5019-df2d-412f-a238-8e24e57f9375 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9d4a5019-df2d-412f-a238-8e24e57f9375');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#최소, 최대, 평균 길이\n",
        "q_len = [len(s.split()) for s in data['QQ']]\n",
        "a_len = [len(s.split()) for s in data['AA']]\n",
        "\n",
        "print('q의 최소 길이 : {}'.format(np.min(q_len)))\n",
        "print('q의 최대 길이 : {}'.format(np.max(q_len)))\n",
        "print('q의 평균 길이 : {}'.format(np.mean(q_len)))\n",
        "print('a의 최소 길이 : {}'.format(np.min(a_len)))\n",
        "print('a의 최대 길이 : {}'.format(np.max(a_len)))\n",
        "print('a의 평균 길이 : {}'.format(np.mean(a_len)))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.title('Questions')\n",
        "plt.hist(q_len, bins = 40)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.title('Answers')\n",
        "plt.hist(a_len, bins = 40)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "VDEZ2firnHcy",
        "outputId": "f8470ef6-af91-473d-c27a-7d6fed8b3c2b"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "q의 최소 길이 : 1\n",
            "q의 최대 길이 : 16\n",
            "q의 평균 길이 : 3.9371563900871185\n",
            "a의 최소 길이 : 1\n",
            "a의 최대 길이 : 24\n",
            "a의 평균 길이 : 4.715300685105303\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "step3. SubwordTextEncoder사용하기"
      ],
      "metadata": {
        "id": "QcEfaiNEaBjo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#단어장 만들기\n",
        "questions = []\n",
        "answers = []\n",
        "\n",
        "for qq in data[\"QQ\"]:\n",
        "  questions.append(qq)\n",
        "\n",
        "for aa in data[\"AA\"]:\n",
        "  answers.append(aa)\n",
        "\n",
        "#임의로 22번째 샘플(인덱스 상으로는 21번 샘플)을 출력\n",
        "\n",
        "print('전처리 후의 22번째 질문 샘플: {}'.format(questions[21]))\n",
        "print('전처리 후의 22번째 답변 샘플: {}'.format(answers[21]))\n",
        "\n",
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mS8ouOD3aEJr",
        "outputId": "df1218d0-8d0f-4097-a931-3ebcd7d95d26"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전처리 후의 22번째 질문 샘플: 가스비 장난 아님\n",
            "전처리 후의 22번째 답변 샘플: 다음 달에는 더 절약해봐요 .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#시작 토큰과 종료 토큰에 고유한 정수를 부여\n",
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
        "\n",
        "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
        "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])\n",
        "\n",
        "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
        "print(VOCAB_SIZE)  #8161"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkPmK_okdUYQ",
        "outputId": "9f70d164-c0a9-4d9a-a16a-4efd7932f8be"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "START_TOKEN의 번호 : [8159]\n",
            "END_TOKEN의 번호 : [8160]\n",
            "8161\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#단어 정수인코딩 & 최대길이 초과샘플 제거 & 패딩\n",
        "MAX_LENGTH = 12\n",
        "\n",
        "def tokenize_and_filter(inputs, outputs):\n",
        "  tokenized_inputs, tokenized_outputs = [], []\n",
        "  \n",
        "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
        "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
        "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
        "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
        "\n",
        "    # 최대 길이 12 이하인 경우에만 데이터셋으로 허용\n",
        "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
        "      tokenized_inputs.append(sentence1)\n",
        "      tokenized_outputs.append(sentence2)\n",
        "  \n",
        "  # 최대 길이 12 로 모든 데이터셋을 패딩\n",
        "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  \n",
        "  return tokenized_inputs, tokenized_outputs\n",
        "\n",
        "\n",
        "questions, answers = tokenize_and_filter(questions, answers)\n",
        "print('단어장의 크기 :',(VOCAB_SIZE))\n",
        "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))   #10744\n",
        "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))     #10744"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXmWyYqpdbFI",
        "outputId": "7c818eb5-85eb-4b61-f192-c867817bd209"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어장의 크기 : 8161\n",
            "필터링 후의 질문 샘플 개수: 10744\n",
            "필터링 후의 답변 샘플 개수: 10744\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#질문과 답변의 쌍을 tf.data.Dataset API의 입력으로 사용하여 파이프라인을 구성\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 20000\n",
        "\n",
        "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
        "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'inputs': questions,\n",
        "        'dec_inputs': answers[:, :-1]    #교사강요를 위한 디코더의 입력값\n",
        "    },\n",
        "    {\n",
        "        'outputs': answers[:, 1:]        #교사강요를 위한 디코더의 레이블 \n",
        "    },\n",
        "))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "metadata": {
        "id": "JGinLl2udrWX"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "step4. 모델 구성하기"
      ],
      "metadata": {
        "id": "f_PwNcgxaFQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#포지셔널 인코딩 레이어\n",
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, position, d_model):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    # 각도 배열 생성\n",
        "    angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "\n",
        "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    # sin과 cosine이 교차되도록 재배열\n",
        "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
        "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
        "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
        "\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ],
      "metadata": {
        "id": "FXCSHbuUd1ee"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sclaed dot product attention fn.\n",
        "\n",
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "  # 가중치를 정규화\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "  # 패딩에 마스크 추가\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9)\n",
        "\n",
        "  # softmax적용\n",
        "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
        "  output = tf.matmul(attention_weights, value)\n",
        "  return output"
      ],
      "metadata": {
        "id": "FSXOB8S_d3M6"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#멀티헤드 어텐션\n",
        "#https://velog.io/@cha-suyeon/%EB%A9%80%ED%8B%B0-%ED%97%A4%EB%93%9C-%EC%96%B4%ED%85%90%EC%85%98Multi-head-Attention-%EA%B5%AC%ED%98%84%ED%95%98%EA%B8%B0\n",
        "\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(\n",
        "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "        'value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    # Q, K, V에 각각 Dense를 적용합니다\n",
        "    query = self.query_dense(query) \n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
        "    query = self.split_heads(query, batch_size) \n",
        "    key = self.split_heads(key, batch_size) \n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    # 스케일드 닷 프로덕트 어텐션 함수\n",
        "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "\n",
        "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "PSP2p3kkd5Sn"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#패딩마스킹\n",
        "def create_padding_mask(x):\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  # (batch_size, 1, 1, sequence length)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "\n",
        "#룩 어헤드 마스킹\n",
        "def create_look_ahead_mask(x):\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "  padding_mask = create_padding_mask(x)\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)   ##패딩마스킹도 포함해서 결과 추출 "
      ],
      "metadata": {
        "id": "F0c86F4Cd7Aj"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1개의 인코더 층\n",
        "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "\n",
        "  # 패딩 마스크 사용\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "\n",
        "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
        "  \n",
        "  \n",
        "#인코더 정의\n",
        "\n",
        "def encoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"encoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "\n",
        "  # 패딩 마스크 사용\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  # 임베딩 레이어\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "\n",
        "  # 포지셔널 인코딩\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  # num_layers만큼 쌓아올린 인코더의 층.\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name=\"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "metadata": {
        "id": "fNoaa1SaeATf"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 디코더 하나의 레이어를 함수로 구현.\n",
        "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
        "  attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': look_ahead_mask\n",
        "      })\n",
        "\n",
        "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  attention1 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "  # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
        "  attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query': attention1,\n",
        "          'key': enc_outputs,\n",
        "          'value': enc_outputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "\n",
        "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
        "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "  attention2 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)\n",
        "  \n",
        "\n",
        "#디코더 정의\n",
        "def decoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name='decoder'):\n",
        "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name='look_ahead_mask')\n",
        "\n",
        "  # 패딩 마스크\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "  \n",
        "  # 임베딩 레이어\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "\n",
        "  # 포지셔널 인코딩\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name='decoder_layer_{}'.format(i),\n",
        "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "metadata": {
        "id": "MNiE05YfeFEN"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                name=\"transformer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "  # 인코더에서 패딩을 위한 마스크\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(inputs)\n",
        "\n",
        "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
        "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask,\n",
        "      output_shape=(1, None, None),\n",
        "      name='look_ahead_mask')(dec_inputs)\n",
        "\n",
        "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
        "  # 디코더에서 패딩을 위한 마스크\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='dec_padding_mask')(inputs)\n",
        "\n",
        "  # 인코더\n",
        "  enc_outputs = encoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "  # 디코더\n",
        "  dec_outputs = decoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  # 완전연결층\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ],
      "metadata": {
        "id": "qLEGxp4laGco"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 생성\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# 하이퍼파라미터\n",
        "NUM_LAYERS = 6 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.1 # 드롭아웃의 비율\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpTT1orDeMyr",
        "outputId": "e32a4fbd-f2e6-4884-c9bf-356847b2b600"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inputs (InputLayer)            [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, None, 256)    5251840     ['inputs[0][0]',                 \n",
            "                                                                  'enc_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
            "                                e)                                                                \n",
            "                                                                                                  \n",
            " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, None, 256)    6833920     ['dec_inputs[0][0]',             \n",
            "                                                                  'encoder[0][0]',                \n",
            "                                                                  'look_ahead_mask[0][0]',        \n",
            "                                                                  'dec_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, None, 8161)   2097377     ['decoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 14,183,137\n",
            "Trainable params: 14,183,137\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "step5. 모델 평가하기"
      ],
      "metadata": {
        "id": "8bnYti-kaG5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#손실함수: 레이블인 시퀀스에 패딩이 되어 있으므로, loss를 계산할 때 패딩 마스크를 적용\n",
        "\n",
        "def loss_function(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  \n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\n",
        "\n",
        "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
        "  loss = tf.multiply(loss, mask)\n",
        "\n",
        "  return tf.reduce_mean(loss)\n",
        "\n",
        "\n",
        "#Learning rate: 커스텀 학습률 스케줄링(Custom Learning rate Scheduling)\n",
        "\n",
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    step = tf.cast(step, tf.float32)   #optimizer선언할때 에러나서 추가 \n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "metadata": {
        "id": "eZRZ-0BYaII8"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델컴파일\n",
        "\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "metadata": {
        "id": "rc_-lKfteTYb"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#학습진행\n",
        "es = EarlyStopping(monitor='loss', patience=3, verbose=1)\n",
        "\n",
        "EPOCHS = 100\n",
        "model.fit(dataset, epochs=EPOCHS, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1xWMBEPeV3Q",
        "outputId": "7304931f-5046-418e-cd2f-c6befdbdb4c4"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "168/168 [==============================] - 88s 179ms/step - loss: 4.7805 - accuracy: 0.0780\n",
            "Epoch 2/100\n",
            "168/168 [==============================] - 15s 90ms/step - loss: 4.0005 - accuracy: 0.1437\n",
            "Epoch 3/100\n",
            "168/168 [==============================] - 15s 88ms/step - loss: 3.3529 - accuracy: 0.1768\n",
            "Epoch 4/100\n",
            "168/168 [==============================] - 14s 83ms/step - loss: 3.0991 - accuracy: 0.1821\n",
            "Epoch 5/100\n",
            "168/168 [==============================] - 15s 87ms/step - loss: 2.9731 - accuracy: 0.1887\n",
            "Epoch 6/100\n",
            "168/168 [==============================] - 14s 83ms/step - loss: 2.8712 - accuracy: 0.1933\n",
            "Epoch 7/100\n",
            "168/168 [==============================] - 14s 81ms/step - loss: 2.7746 - accuracy: 0.1982\n",
            "Epoch 8/100\n",
            "168/168 [==============================] - 14s 84ms/step - loss: 2.6733 - accuracy: 0.2047\n",
            "Epoch 9/100\n",
            "168/168 [==============================] - 14s 84ms/step - loss: 2.5610 - accuracy: 0.2119\n",
            "Epoch 10/100\n",
            "168/168 [==============================] - 14s 81ms/step - loss: 2.4350 - accuracy: 0.2199\n",
            "Epoch 11/100\n",
            "168/168 [==============================] - 14s 81ms/step - loss: 2.2960 - accuracy: 0.2308\n",
            "Epoch 12/100\n",
            "168/168 [==============================] - 14s 81ms/step - loss: 2.1432 - accuracy: 0.2448\n",
            "Epoch 13/100\n",
            "168/168 [==============================] - 13s 80ms/step - loss: 1.9919 - accuracy: 0.2594\n",
            "Epoch 14/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 1.8312 - accuracy: 0.2785\n",
            "Epoch 15/100\n",
            "168/168 [==============================] - 14s 82ms/step - loss: 1.6767 - accuracy: 0.2981\n",
            "Epoch 16/100\n",
            "168/168 [==============================] - 13s 80ms/step - loss: 1.5386 - accuracy: 0.3164\n",
            "Epoch 17/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 1.4072 - accuracy: 0.3353\n",
            "Epoch 18/100\n",
            "168/168 [==============================] - 14s 82ms/step - loss: 1.2947 - accuracy: 0.3498\n",
            "Epoch 19/100\n",
            "168/168 [==============================] - 14s 82ms/step - loss: 1.1990 - accuracy: 0.3631\n",
            "Epoch 20/100\n",
            "168/168 [==============================] - 14s 81ms/step - loss: 1.1280 - accuracy: 0.3731\n",
            "Epoch 21/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 1.0738 - accuracy: 0.3809\n",
            "Epoch 22/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 1.0252 - accuracy: 0.3889\n",
            "Epoch 23/100\n",
            "168/168 [==============================] - 14s 81ms/step - loss: 0.9880 - accuracy: 0.3958\n",
            "Epoch 24/100\n",
            "168/168 [==============================] - 13s 80ms/step - loss: 0.9675 - accuracy: 0.3974\n",
            "Epoch 25/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.9334 - accuracy: 0.4044\n",
            "Epoch 26/100\n",
            "168/168 [==============================] - 14s 81ms/step - loss: 0.8968 - accuracy: 0.4102\n",
            "Epoch 27/100\n",
            "168/168 [==============================] - 13s 80ms/step - loss: 0.8611 - accuracy: 0.4167\n",
            "Epoch 28/100\n",
            "168/168 [==============================] - 13s 80ms/step - loss: 0.8357 - accuracy: 0.4200\n",
            "Epoch 29/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.8131 - accuracy: 0.4237\n",
            "Epoch 30/100\n",
            "168/168 [==============================] - 13s 80ms/step - loss: 0.7874 - accuracy: 0.4266\n",
            "Epoch 31/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.7660 - accuracy: 0.4305\n",
            "Epoch 32/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.7457 - accuracy: 0.4332\n",
            "Epoch 33/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.7305 - accuracy: 0.4345\n",
            "Epoch 34/100\n",
            "168/168 [==============================] - 13s 80ms/step - loss: 0.7131 - accuracy: 0.4374\n",
            "Epoch 35/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.6982 - accuracy: 0.4390\n",
            "Epoch 36/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.6847 - accuracy: 0.4429\n",
            "Epoch 37/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.6719 - accuracy: 0.4435\n",
            "Epoch 38/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.6600 - accuracy: 0.4447\n",
            "Epoch 39/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.6486 - accuracy: 0.4465\n",
            "Epoch 40/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.6355 - accuracy: 0.4488\n",
            "Epoch 41/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.6261 - accuracy: 0.4500\n",
            "Epoch 42/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.6170 - accuracy: 0.4514\n",
            "Epoch 43/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.6063 - accuracy: 0.4524\n",
            "Epoch 44/100\n",
            "168/168 [==============================] - 13s 80ms/step - loss: 0.5987 - accuracy: 0.4535\n",
            "Epoch 45/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.5904 - accuracy: 0.4548\n",
            "Epoch 46/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.5812 - accuracy: 0.4554\n",
            "Epoch 47/100\n",
            "168/168 [==============================] - 14s 80ms/step - loss: 0.5708 - accuracy: 0.4580\n",
            "Epoch 48/100\n",
            "168/168 [==============================] - 13s 80ms/step - loss: 0.5658 - accuracy: 0.4584\n",
            "Epoch 49/100\n",
            "168/168 [==============================] - 13s 80ms/step - loss: 0.5573 - accuracy: 0.4594\n",
            "Epoch 50/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.5529 - accuracy: 0.4600\n",
            "Epoch 51/100\n",
            "168/168 [==============================] - 13s 80ms/step - loss: 0.5439 - accuracy: 0.4612\n",
            "Epoch 52/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.5389 - accuracy: 0.4624\n",
            "Epoch 53/100\n",
            "168/168 [==============================] - 13s 78ms/step - loss: 0.5340 - accuracy: 0.4619\n",
            "Epoch 54/100\n",
            "168/168 [==============================] - 13s 78ms/step - loss: 0.5299 - accuracy: 0.4631\n",
            "Epoch 55/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.5207 - accuracy: 0.4645\n",
            "Epoch 56/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.5170 - accuracy: 0.4644\n",
            "Epoch 57/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.5108 - accuracy: 0.4661\n",
            "Epoch 58/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.5030 - accuracy: 0.4674\n",
            "Epoch 59/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.5019 - accuracy: 0.4668\n",
            "Epoch 60/100\n",
            "168/168 [==============================] - 14s 81ms/step - loss: 0.4993 - accuracy: 0.4675\n",
            "Epoch 61/100\n",
            "168/168 [==============================] - 13s 78ms/step - loss: 0.4914 - accuracy: 0.4682\n",
            "Epoch 62/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.4880 - accuracy: 0.4691\n",
            "Epoch 63/100\n",
            "168/168 [==============================] - 13s 80ms/step - loss: 0.4813 - accuracy: 0.4705\n",
            "Epoch 64/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.4765 - accuracy: 0.4707\n",
            "Epoch 65/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.4721 - accuracy: 0.4719\n",
            "Epoch 66/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.4706 - accuracy: 0.4715\n",
            "Epoch 67/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.4652 - accuracy: 0.4728\n",
            "Epoch 68/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.4615 - accuracy: 0.4736\n",
            "Epoch 69/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.4558 - accuracy: 0.4738\n",
            "Epoch 70/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.4553 - accuracy: 0.4747\n",
            "Epoch 71/100\n",
            "168/168 [==============================] - 13s 80ms/step - loss: 0.4495 - accuracy: 0.4755\n",
            "Epoch 72/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.4467 - accuracy: 0.4755\n",
            "Epoch 73/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.4451 - accuracy: 0.4757\n",
            "Epoch 74/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.4401 - accuracy: 0.4763\n",
            "Epoch 75/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.4357 - accuracy: 0.4773\n",
            "Epoch 76/100\n",
            "168/168 [==============================] - 13s 80ms/step - loss: 0.4345 - accuracy: 0.4769\n",
            "Epoch 77/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.4316 - accuracy: 0.4778\n",
            "Epoch 78/100\n",
            "168/168 [==============================] - 13s 78ms/step - loss: 0.4281 - accuracy: 0.4787\n",
            "Epoch 79/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.4224 - accuracy: 0.4790\n",
            "Epoch 80/100\n",
            "168/168 [==============================] - 13s 80ms/step - loss: 0.4199 - accuracy: 0.4800\n",
            "Epoch 81/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.4163 - accuracy: 0.4801\n",
            "Epoch 82/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.4151 - accuracy: 0.4801\n",
            "Epoch 83/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.4158 - accuracy: 0.4804\n",
            "Epoch 84/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.4097 - accuracy: 0.4817\n",
            "Epoch 85/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.4057 - accuracy: 0.4820\n",
            "Epoch 86/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.4066 - accuracy: 0.4813\n",
            "Epoch 87/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.4008 - accuracy: 0.4828\n",
            "Epoch 88/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.3978 - accuracy: 0.4831\n",
            "Epoch 89/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.3983 - accuracy: 0.4836\n",
            "Epoch 90/100\n",
            "168/168 [==============================] - 14s 81ms/step - loss: 0.3938 - accuracy: 0.4841\n",
            "Epoch 91/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.3922 - accuracy: 0.4842\n",
            "Epoch 92/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.3890 - accuracy: 0.4845\n",
            "Epoch 93/100\n",
            "168/168 [==============================] - 13s 80ms/step - loss: 0.3837 - accuracy: 0.4857\n",
            "Epoch 94/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.3856 - accuracy: 0.4844\n",
            "Epoch 95/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.3803 - accuracy: 0.4858\n",
            "Epoch 96/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.3775 - accuracy: 0.4864\n",
            "Epoch 97/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.3779 - accuracy: 0.4861\n",
            "Epoch 98/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.3770 - accuracy: 0.4863\n",
            "Epoch 99/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.3721 - accuracy: 0.4878\n",
            "Epoch 100/100\n",
            "168/168 [==============================] - 13s 79ms/step - loss: 0.3709 - accuracy: 0.4878\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc1cffb8430>"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "챗봇 테스트"
      ],
      "metadata": {
        "id": "T_kLvdLKedMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#예측 함수 \n",
        "def decoder_inference(sentence):\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
        "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
        "  sentence = tf.expand_dims(\n",
        "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
        "\n",
        "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
        "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
        "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
        "\n",
        "  # 디코더의 인퍼런스 단계\n",
        "  for i in range(MAX_LENGTH):\n",
        "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
        "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
        "    predictions = predictions[:, -1:, :]\n",
        "\n",
        "    # 현재 예측한 단어의 정수\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
        "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
        "      break\n",
        "\n",
        "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
        "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
        "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output_sequence, axis=0)\n",
        "\n",
        "\n",
        "\n",
        "#챗봇 대답얻는 함수\n",
        "def sentence_generation(sentence):\n",
        "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
        "  prediction = decoder_inference(sentence)\n",
        "\n",
        "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
        "  predicted_sentence = tokenizer.decode(\n",
        "      [i for i in prediction if i < tokenizer.vocab_size])\n",
        "\n",
        "  print('입력 : {}'.format(sentence))\n",
        "  print('출력 : {}'.format(predicted_sentence))\n",
        "\n",
        "  return predicted_sentence"
      ],
      "metadata": {
        "id": "asn_KCxEeY5n"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#테스트\n",
        "sentence_generation('안녕?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "M9fPm8cYegzk",
        "outputId": "0e26ea99-ce27-4d14-8d73-b6b9c43efa60"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 안녕?\n",
            "출력 : 안녕하세요 .\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'안녕하세요 .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_generation(\"퇴근하고 뭐해?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "PXGdlyrVfD7c",
        "outputId": "b186612c-c9ab-4968-c21a-b8b02a395aa0"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 퇴근하고 뭐해?\n",
            "출력 : 즐거운 시간이 될 거 같아요\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'즐거운 시간이 될 거 같아요'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    }
  ]
}